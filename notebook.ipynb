{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hypothesis Testing in Python\n",
                "\n",
                "## Hypothesis Testing Fundamentals\n",
                "\n",
                "### Calculating the sample mean\n",
                "\n",
                "The `late_shipments` dataset contains supply chain data on the delivery\n",
                "of medical supplies. Each row represents one delivery of a part. The\n",
                "`late` columns denotes whether or not the part was delivered late. A\n",
                "value of `\"Yes\"` means that the part was delivered late, and a value of\n",
                "`\"No\"` means the part was delivered on time.\n",
                "\n",
                "You'll begin your analysis by calculating a point estimate (or sample\n",
                "statistic), namely the proportion of late shipments.\n",
                "\n",
                "In `pandas`, a value's proportion in a categorical DataFrame column can\n",
                "be quickly calculated using the syntax:\n",
                "\n",
                "    prop = (df['col'] == val).mean()\n",
                "\n",
                "`late_shipments` is available, and `pandas` is loaded as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Print the `late_shipments` dataset.\n",
                "- Calculate the proportion of late shipments in the sample; that is, the mean cases where the `late` column is `\"Yes\"`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.12/site-packages (2.2.2)\n",
                        "Collecting pyarrow\n",
                        "  Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (3.0 kB)\n",
                        "Requirement already satisfied: numpy>=1.26.0 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
                        "Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl (38.1 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: pyarrow\n",
                        "Successfully installed pyarrow-16.1.0\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install pandas pyarrow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import pandas as pd\n",
                "late_shipments = pd.read_feather('late_shipments.feather')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "          id       country managed_by  fulfill_via vendor_inco_term  \\\n",
                        "0    36203.0       Nigeria   PMO - US  Direct Drop              EXW   \n",
                        "1    30998.0      Botswana   PMO - US  Direct Drop              EXW   \n",
                        "2    69871.0       Vietnam   PMO - US  Direct Drop              EXW   \n",
                        "3    17648.0  South Africa   PMO - US  Direct Drop              DDP   \n",
                        "4     5647.0        Uganda   PMO - US  Direct Drop              EXW   \n",
                        "..       ...           ...        ...          ...              ...   \n",
                        "995  13608.0        Uganda   PMO - US  Direct Drop              DDP   \n",
                        "996  80394.0    Congo, DRC   PMO - US  Direct Drop              EXW   \n",
                        "997  61675.0        Zambia   PMO - US  Direct Drop              EXW   \n",
                        "998  39182.0  South Africa   PMO - US  Direct Drop              DDP   \n",
                        "999   5645.0      Botswana   PMO - US  Direct Drop              EXW   \n",
                        "\n",
                        "    shipment_mode  late_delivery late product_group    sub_classification  \\\n",
                        "0             Air            1.0  Yes          HRDT              HIV test   \n",
                        "1             Air            0.0   No          HRDT              HIV test   \n",
                        "2             Air            0.0   No           ARV                 Adult   \n",
                        "3           Ocean            0.0   No           ARV                 Adult   \n",
                        "4             Air            0.0   No          HRDT  HIV test - Ancillary   \n",
                        "..            ...            ...  ...           ...                   ...   \n",
                        "995           Air            0.0   No           ARV                 Adult   \n",
                        "996           Air            0.0   No          HRDT              HIV test   \n",
                        "997           Air            1.0  Yes          HRDT              HIV test   \n",
                        "998         Ocean            0.0   No           ARV                 Adult   \n",
                        "999           Air            0.0   No          HRDT              HIV test   \n",
                        "\n",
                        "     ... line_item_quantity line_item_value pack_price unit_price  \\\n",
                        "0    ...             2996.0       266644.00      89.00       0.89   \n",
                        "1    ...               25.0          800.00      32.00       1.60   \n",
                        "2    ...            22925.0       110040.00       4.80       0.08   \n",
                        "3    ...           152535.0       361507.95       2.37       0.04   \n",
                        "4    ...              850.0            8.50       0.01       0.00   \n",
                        "..   ...                ...             ...        ...        ...   \n",
                        "995  ...              121.0         9075.00      75.00       0.62   \n",
                        "996  ...              292.0         9344.00      32.00       1.60   \n",
                        "997  ...             2127.0       170160.00      80.00       0.80   \n",
                        "998  ...           191011.0       861459.61       4.51       0.15   \n",
                        "999  ...              200.0        14398.00      71.99       0.72   \n",
                        "\n",
                        "               manufacturing_site first_line_designation  weight_kilograms  \\\n",
                        "0         Alere Medical Co., Ltd.                    Yes            1426.0   \n",
                        "1            Trinity Biotech, Plc                    Yes              10.0   \n",
                        "2    Hetero Unit III Hyderabad IN                    Yes            3723.0   \n",
                        "3       Aurobindo Unit III, India                    Yes            7698.0   \n",
                        "4                 Inverness Japan                    Yes              56.0   \n",
                        "..                            ...                    ...               ...   \n",
                        "995     Janssen-Cilag, Latina, IT                    Yes              43.0   \n",
                        "996          Trinity Biotech, Plc                    Yes              99.0   \n",
                        "997       Alere Medical Co., Ltd.                    Yes             881.0   \n",
                        "998     Aurobindo Unit III, India                    Yes           16234.0   \n",
                        "999               Inverness Japan                    Yes              46.0   \n",
                        "\n",
                        "     freight_cost_usd  freight_cost_groups  line_item_insurance_usd  \n",
                        "0            33279.83            expensive                   373.83  \n",
                        "1              559.89           reasonable                     1.72  \n",
                        "2            19056.13            expensive                   181.57  \n",
                        "3            11372.23            expensive                   779.41  \n",
                        "4              360.00           reasonable                     0.01  \n",
                        "..                ...                  ...                      ...  \n",
                        "995            199.00           reasonable                    12.72  \n",
                        "996           2162.55           reasonable                    13.10  \n",
                        "997          14019.38            expensive                   210.49  \n",
                        "998          14439.17            expensive                  1421.41  \n",
                        "999           1028.18           reasonable                    23.04  \n",
                        "\n",
                        "[1000 rows x 27 columns]\n",
                        "0.061\n"
                    ]
                }
            ],
            "source": [
                "# Print the late_shipments dataset\n",
                "print(late_shipments)\n",
                "\n",
                "# Calculate the proportion of late shipments\n",
                "late_prop_samp = (late_shipments['late'] == \"Yes\").mean()\n",
                "\n",
                "# Print the results\n",
                "print(late_prop_samp)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculating a z-score\n",
                "\n",
                "Since variables have arbitrary ranges and units, we need to standardize\n",
                "them. For example, a hypothesis test that gave different answers if the\n",
                "variables were in Euros instead of US dollars would be of little value.\n",
                "Standardization avoids that.\n",
                "\n",
                "One standardized value of interest in a hypothesis test is called a\n",
                "z-score. To calculate it, you need three numbers: the sample statistic\n",
                "(point estimate), the hypothesized statistic, and the standard error of\n",
                "the statistic (estimated from the bootstrap distribution).\n",
                "\n",
                "The sample statistic is available as `late_prop_samp`.\n",
                "\n",
                "`late_shipments_boot_distn` is a bootstrap distribution of the\n",
                "proportion of late shipments, available as a list.\n",
                "\n",
                "`pandas` and `numpy` are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Hypothesize that the proportion of late shipments is 6%.\n",
                "- Calculate the standard error from the standard deviation of the\n",
                "  bootstrap distribution.\n",
                "- Calculate the z-score.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import numpy as np\n",
                "late_shipments_boot_distn = [\n",
                "    late_shipments.sample(n=len(late_shipments), replace=True)['late_delivery'].mean()\n",
                "    for _ in range(5000)\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.13000327219181468\n"
                    ]
                }
            ],
            "source": [
                "# Hypothesize that the proportion is 6%\n",
                "late_prop_hyp = 0.06\n",
                "\n",
                "# Calculate the standard error\n",
                "std_error = np.std(late_shipments_boot_distn, ddof=1)\n",
                "\n",
                "# Find z-score of late_prop_samp\n",
                "z_score = (late_prop_samp - late_prop_hyp) / std_error\n",
                "\n",
                "# Print z_score\n",
                "print(z_score)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculating p-values\n",
                "\n",
                "In order to determine whether to choose the null hypothesis or the\n",
                "alternative hypothesis, you need to calculate a p-value from the\n",
                "z-score.\n",
                "\n",
                "You'll now return to the late shipments dataset and the proportion of\n",
                "late shipments.\n",
                "\n",
                "The null hypothesis, \\\\H\\_{0}\\\\, is that the proportion of late\n",
                "shipments is six percent.\n",
                "\n",
                "The alternative hypothesis, \\\\H\\_{A}\\\\, is that the proportion of late\n",
                "shipments is **greater than** six percent.\n",
                "\n",
                "The observed sample statistic, `late_prop_samp`, the hypothesized value,\n",
                "`late_prop_hyp` (6%), and the bootstrap standard error, `std_error` are\n",
                "available. `norm` from `scipy.stats` has also been loaded without an\n",
                "alias.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the z-score of `late_prop_samp`.\n",
                "- Calculate the p-value for the z-score, using a right-tailed test.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Collecting scipy\n",
                        "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (113 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.22.4 in /home/vscode/.local/lib/python3.12/site-packages (from scipy) (1.26.4)\n",
                        "Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (33.4 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: scipy\n",
                        "Successfully installed scipy-1.13.1\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install scipy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "from scipy.stats import norm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.4482819189143381\n"
                    ]
                }
            ],
            "source": [
                "# Calculate the z-score of late_prop_samp\n",
                "z_score = (late_prop_samp - late_prop_hyp) / std_error\n",
                "\n",
                "# Calculate the p-value\n",
                "p_value = 1 - norm.cdf(z_score)\n",
                "                 \n",
                "# Print the p-value\n",
                "print(p_value) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculating a confidence interval\n",
                "\n",
                "If you give a single estimate of a sample statistic, you are bound to be\n",
                "wrong by some amount. For example, the hypothesized proportion of late\n",
                "shipments was 6%. Even if evidence suggests the null hypothesis that the\n",
                "proportion of late shipments is equal to this, for any new sample of\n",
                "shipments, the proportion is likely to be a little different due to\n",
                "sampling variability. Consequently, it's a good idea to state a\n",
                "confidence interval. That is, you say, \"we are 95% 'confident' that the\n",
                "proportion of late shipments is between A and B\" (for some value of A\n",
                "and B).\n",
                "\n",
                "Sampling in Python\n",
                "[demonstrated](https://campus.datacamp.com/courses/sampling-in-python/bootstrap-distributions-4?ex=10)\n",
                "two methods for calculating confidence intervals. Here, you'll use\n",
                "quantiles of the bootstrap distribution to calculate the confidence\n",
                "interval.\n",
                "\n",
                "`late_prop_samp` and `late_shipments_boot_distn` are available; `pandas`\n",
                "and `numpy` are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate a 95% confidence interval from `late_shipments_boot_distn`\n",
                "  using the quantile method, labeling the lower and upper intervals\n",
                "  `lower` and `upper`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(0.046, 0.076)\n"
                    ]
                }
            ],
            "source": [
                "# Calculate 95% confidence interval using quantile method\n",
                "lower = np.quantile(late_shipments_boot_distn, 0.025)\n",
                "upper = np.quantile(late_shipments_boot_distn, 0.975)\n",
                "\n",
                "# Print the confidence interval\n",
                "print((lower, upper))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Two-Sample and ANOVA Tests\n",
                "\n",
                "### Two sample mean test statistic\n",
                "\n",
                "The hypothesis test for determining if there is a difference between the\n",
                "means of two populations uses a different type of test statistic to the\n",
                "z-scores you saw in Chapter 1. It's called \"t\", and it can be calculated\n",
                "from three values from each sample using this equation.\n",
                "\n",
                "\\$\\$ t = \\dfrac{(\\bar{x}\\_{\\text{child}} -\n",
                "\\bar{x}\\_{\\text{adult}})}{\\sqrt{\\dfrac{s\\_{\\text{child}}^2}{n\\_{\\text{child}}} +\n",
                "\\dfrac{s\\_{\\text{adult}}^2}{n\\_{\\text{adult}}}}} \\$\\$\n",
                "\n",
                "While trying to determine why some shipments are late, you may wonder if\n",
                "the weight of the shipments that were on time is **less than** the\n",
                "weight of the shipments that were late. The `late_shipments` dataset has\n",
                "been split into a \"yes\" group, where `late == \"Yes\"` and a \"no\" group\n",
                "where `late == \"No\"`. The weight of the shipment is given in the\n",
                "`weight_kilograms` variable.\n",
                "\n",
                "The sample means for the two groups are available as `xbar_no` and\n",
                "`xbar_yes`. The sample standard deviations are `s_no` and `s_yes`. The\n",
                "sample sizes are `n_no` and `n_yes`. `numpy` is also loaded as `np`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the numerator of the \\\\t\\\\ test statistic.\n",
                "- Calculate the denominator of the \\\\t\\\\ test statistic.\n",
                "- Use those two numbers to calculate the \\\\t\\\\ test statistic.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'xbar_no' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the numerator of the test statistic\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m numerator \u001b[38;5;241m=\u001b[39m \u001b[43mxbar_no\u001b[49m \u001b[38;5;241m-\u001b[39m xbar_yes\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate the denominator of the test statistic\u001b[39;00m\n\u001b[1;32m      5\u001b[0m denominator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(s_no \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m n_no \u001b[38;5;241m+\u001b[39m s_yes \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m n_yes)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'xbar_no' is not defined"
                    ]
                }
            ],
            "source": [
                "# Calculate the numerator of the test statistic\n",
                "numerator = xbar_no - xbar_yes\n",
                "\n",
                "# Calculate the denominator of the test statistic\n",
                "denominator = np.sqrt(s_no ** 2 / n_no + s_yes ** 2 / n_yes)\n",
                "\n",
                "# Calculate the test statistic\n",
                "t_stat = numerator / denominator\n",
                "\n",
                "# Print the test statistic\n",
                "print(t_stat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### From t to p\n",
                "\n",
                "Previously, you calculated the test statistic for the two-sample problem\n",
                "of whether the mean weight of shipments is smaller for shipments that\n",
                "weren't late (`late == \"No\"`) compared to shipments that were late\n",
                "(`late == \"Yes\"`). In order to make decisions about it, you need to\n",
                "transform the test statistic with a cumulative distribution function to\n",
                "get a p-value.\n",
                "\n",
                "Recall the hypotheses:\n",
                "\n",
                "\\\\H\\_{0}\\\\: The mean weight of shipments that weren't late is the same\n",
                "as the mean weight of shipments that were late.\n",
                "\n",
                "\\\\H\\_{A}\\\\: The mean weight of shipments that weren't late is less than\n",
                "the mean weight of shipments that were late.\n",
                "\n",
                "The test statistic, `t_stat`, is available, as are the samples sizes for\n",
                "each group, `n_no` and `n_yes`. Use a significance level of\n",
                "`alpha = 0.05`.\n",
                "\n",
                "`t` has also been imported from `scipy.stats`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the degrees of freedom for the test.\n",
                "- Compute the p-value using the test statistic, `t_stat`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the degrees of freedom\n",
                "degrees_of_freedom = n_no + n_yes - 2\n",
                "\n",
                "# Calculate the p-value from the test stat\n",
                "p_value = t.cdf(t_stat, df=degrees_of_freedom)\n",
                "\n",
                "# Print the p_value\n",
                "print(p_value)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing the difference\n",
                "\n",
                "Before you start running hypothesis tests, it's a great idea to perform\n",
                "some exploratory data analysis; that is, calculating summary statistics\n",
                "and visualizing distributions.\n",
                "\n",
                "Here, you'll look at the proportion of county-level votes for the\n",
                "Democratic candidate in 2012 and 2016, `sample_dem_data`. Since the\n",
                "counties are the same in both years, these samples are paired. The\n",
                "columns containing the samples are `dem_percent_12` and\n",
                "`dem_percent_16`.\n",
                "\n",
                "`dem_votes_potus_12_16` is available as `sample_dem_data`. `pandas` and\n",
                "`matplotlib.pyplot` are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a new `diff` column containing the percentage of votes for the\n",
                "  democratic candidate in 2012 minus the percentage of votes for the\n",
                "  democratic candidate in 2016.\n",
                "- Calculate the mean of the `diff` column as `xbar_diff`.\n",
                "- Calculate the standard deviation of the `diff` column as `s_diff`.\n",
                "- Plot a histogram of the `diff` column with 20 bins.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the differences from 2012 to 2016\n",
                "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
                "\n",
                "# Print sample_dem_data\n",
                "print(sample_dem_data)\n",
                "\n",
                "\n",
                "# Calculate the differences from 2012 to 2016\n",
                "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
                "\n",
                "# Find the mean of the diff column\n",
                "xbar_diff = sample_dem_data['diff'].mean()\n",
                "\n",
                "# Print xbar_diff\n",
                "print(xbar_diff)\n",
                "\n",
                "\n",
                "# Calculate the differences from 2012 to 2016\n",
                "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
                "\n",
                "# Find the mean of the diff column\n",
                "xbar_diff = sample_dem_data['diff'].mean()\n",
                "\n",
                "# Find the standard deviation of the diff column\n",
                "s_diff = sample_dem_data['diff'].std()\n",
                "\n",
                "# Print s_diff\n",
                "print(s_diff)\n",
                "\n",
                "\n",
                "# Calculate the differences from 2012 to 2016\n",
                "sample_dem_data['diff'] = sample_dem_data['dem_percent_12'] - sample_dem_data['dem_percent_16']\n",
                "\n",
                "# Find the mean of the diff column\n",
                "xbar_diff = sample_dem_data['diff'].mean()\n",
                "\n",
                "# Find the standard deviation of the diff column\n",
                "s_diff = sample_dem_data['diff'].std()\n",
                "\n",
                "# Plot a histogram of diff with 20 bins\n",
                "sample_dem_data['diff'].hist(bins=20)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Using ttest()\n",
                "\n",
                "Manually calculating test statistics and transforming them with a CDF to\n",
                "get a p-value is a lot of effort to compare two sample means. The\n",
                "comparison of two sample means is called a t-test, and the `pingouin`\n",
                "Python package has a `.ttest()` method to accomplish it. This method\n",
                "provides some flexibility in how you perform the test.\n",
                "\n",
                "As in the previous exercise, you'll explore the difference between the\n",
                "proportion of county-level votes for the Democratic candidate in 2012\n",
                "and 2016 to identify if the difference is significant. The hypotheses\n",
                "are as follows:\n",
                "\n",
                "\\\\H\\_{0}\\\\: The proportion of democratic votes in 2012 and 2016 were the\n",
                "same. \\\\H\\_{A}\\\\: The proportion of democratic votes in 2012 and 2016\n",
                "were different.\n",
                "\n",
                "`sample_dem_data` is available and has the columns `diff`,\n",
                "`dem_percent_12`, and `dem_percent_16` in addition to the `state` and\n",
                "`county` names. `pingouin` and has been loaded along with `pandas` as\n",
                "`pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Conduct a t-test on the sample differences (the `diff` column of\n",
                "  `sample_dem_data`), using an appropriate alternative hypothesis chosen\n",
                "  from `\"two-sided\"`, `\"less\"`, and `\"greater\"`.\n",
                "- Conduct a paired test on the democratic votes in 2012 and 2016 (the `dem_percent_12` and `dem_percent_16` columns of `sample_dem_data`), using an appropriate alternative hypothesis.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conduct a t-test on diff\n",
                "test_results = pingouin.ttest(x=sample_dem_data['diff'], \n",
                "                              y=0, \n",
                "                              alternative=\"two-sided\")\n",
                "                              \n",
                "# Print the test results\n",
                "print(test_results)\n",
                "\n",
                "\n",
                "# Conduct a t-test on diff\n",
                "test_results = pingouin.ttest(x=sample_dem_data['diff'], \n",
                "                              y=0, \n",
                "                              alternative=\"two-sided\")\n",
                "\n",
                "# Conduct a paired t-test on dem_percent_12 and dem_percent_16\n",
                "paired_test_results = pingouin.ttest(x=sample_dem_data['dem_percent_12'], \n",
                "                                     y=sample_dem_data['dem_percent_16'],\n",
                "                                     paired=True,\n",
                "                                     alternative=\"two-sided\")\n",
                "                              \n",
                "# Print the paired test results\n",
                "print(paired_test_results)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing many categories\n",
                "\n",
                "So far in this chapter, we've only considered the case of differences in\n",
                "a numeric variable between two categories. Of course, many datasets\n",
                "contain more categories. Before you get to conducting tests on many\n",
                "categories, it's often helpful to perform exploratory data analysis\n",
                "(EDA), calculating summary statistics for each group and visualizing the\n",
                "distributions of the numeric variable for each category using box plots.\n",
                "\n",
                "Here, we'll return to the late shipments data, and how the price of each\n",
                "package (`pack_price`) varies between the three shipment modes\n",
                "(`shipment_mode`): `\"Air\"`, `\"Air Charter\"`, and `\"Ocean\"`.\n",
                "\n",
                "`late_shipments` is available; `pandas` and `matplotlib.pyplot` are\n",
                "loaded with their standard aliases, and `seaborn` is loaded as `sns`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Group `late_shipments` by `shipment_mode` and calculate the mean\n",
                "  `pack_price` for each group, storing the result in\n",
                "  `xbar_pack_by_mode`.\n",
                "- Group `late_shipments` by `shipment_mode` and calculate the standard deviation `pack_price` for each group, storing the result in `s_pack_by_mode`.\n",
                "- Create a boxplot from `late_shipments` with `\"pack_price\"` as `x` and `\"shipment_mode\"` as `y`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the mean pack_price for each shipment_mode\n",
                "xbar_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].mean()\n",
                "\n",
                "# Print the grouped means\n",
                "print(xbar_pack_by_mode)\n",
                "\n",
                "\n",
                "# Calculate the mean pack_price for each shipment_mode\n",
                "xbar_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].mean()\n",
                "\n",
                "# Calculate the standard deviation of the pack_price for each shipment_mode\n",
                "s_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].std()\n",
                "\n",
                "# Print the grouped standard deviations\n",
                "print(s_pack_by_mode)\n",
                "\n",
                "\n",
                "# Calculate the mean pack_price for each shipment_mode\n",
                "xbar_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].mean()\n",
                "\n",
                "# Calculate the standard deviation of the pack_price for each shipment_mode\n",
                "s_pack_by_mode = late_shipments.groupby(\"shipment_mode\")['pack_price'].std()\n",
                "\n",
                "# Boxplot of shipment_mode vs. pack_price\n",
                "sns.boxplot(x=\"pack_price\", y=\"shipment_mode\", data=late_shipments)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conducting an ANOVA test\n",
                "\n",
                "The box plots made it look like the distribution of pack price was\n",
                "different for each of the three shipment modes. However, it didn't tell\n",
                "us whether the mean pack price was different in each category. To\n",
                "determine that, we can use an ANOVA test. The null and alternative\n",
                "hypotheses can be written as follows.\n",
                "\n",
                "\\\\H\\_{0}\\\\: Pack prices for every category of shipment mode are the\n",
                "same.\n",
                "\n",
                "\\\\H\\_{A}\\\\: Pack prices for some categories of shipment mode are\n",
                "different.\n",
                "\n",
                "Use a significance level of 0.1.\n",
                "\n",
                "`late_shipments` is available and `pingouin` has been loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Run an ANOVA on `late_shipments` investigating `'pack_price'` (the\n",
                "  dependent variable) between the groups of `'shipment_mode'`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run an ANOVA for pack_price across shipment_mode\n",
                "anova_results = pingouin.anova(data=late_shipments,\n",
                "                               dv=\"pack_price\",\n",
                "                               between=\"shipment_mode\")\n",
                "\n",
                "# Print anova_results\n",
                "print(anova_results)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pairwise t-tests\n",
                "\n",
                "The ANOVA test didn't tell you which categories of shipment mode had\n",
                "significant differences in pack prices. To pinpoint which categories had\n",
                "differences, you could instead use pairwise t-tests.\n",
                "\n",
                "`late_shipments` is available and `pingouin` has been loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Perform pairwise t-tests on `late_shipments`'s `pack_price` variable,\n",
                "  grouped by `shipment_mode`, without doing any p-value adjustment.\n",
                "- Modify the pairwise t-tests to use the Bonferroni p-value adjustment.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform a pairwise t-test on pack price, grouped by shipment mode\n",
                "pairwise_results = pingouin.pairwise_tests(data=late_shipments, \n",
                "                                           dv=\"pack_price\",\n",
                "                                           between=\"shipment_mode\",\n",
                "                                           padjust=\"none\")\n",
                "\n",
                "# Print pairwise_results\n",
                "print(pairwise_results)\n",
                "\n",
                "\n",
                "# Modify the pairwise t-tests to use Bonferroni p-value adjustment\n",
                "pairwise_results = pingouin.pairwise_tests(data=late_shipments, \n",
                "                                           dv=\"pack_price\",\n",
                "                                           between=\"shipment_mode\",\n",
                "                                           padjust=\"bonf\")\n",
                "\n",
                "# Print pairwise_results\n",
                "print(pairwise_results)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Proportion Tests\n",
                "\n",
                "### Test for single proportions\n",
                "\n",
                "In Chapter 1, you calculated a p-value for a test hypothesizing that the\n",
                "proportion of late shipments was **greater than** 6%. In that chapter,\n",
                "you used a bootstrap distribution to estimate the standard error of the\n",
                "statistic. An alternative is to use an equation for the standard error\n",
                "based on the sample proportion, hypothesized proportion, and sample\n",
                "size.\n",
                "\n",
                "\\\\z = \\dfrac{\\hat{p} - p\\_{0}}{\\sqrt{\\dfrac{p\\_{0}\\*(1-p\\_{0})}{n}}}\\\\\n",
                "\n",
                "You'll revisit the p-value using this simpler calculation.\n",
                "\n",
                "`late_shipments` is available. `pandas` and `numpy` are available under\n",
                "their usual aliases, and `norm` is loaded from `scipy.stats`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Hypothesize that the proportion of late shipments is 6%.\n",
                "- Calculate the sample proportion of shipments where `late` equals\n",
                "  `\"Yes\"`.\n",
                "- Calculate the number of observations in the sample.\n",
                "- Calculate the numerator and denominator of the z-score.\n",
                "- Calculate the z-score as the ratio of these numbers.\n",
                "- Transform the z-score into a p-value, remembering that this is a \"greater than\" alternative hypothesis.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hypothesize that the proportion of late shipments is 6%\n",
                "p_0 = 0.06\n",
                "\n",
                "# Calculate the sample proportion of late shipments\n",
                "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
                "\n",
                "# Calculate the sample size\n",
                "n = len(late_shipments)\n",
                "\n",
                "# Print p_hat and n\n",
                "print(p_hat, n)\n",
                "\n",
                "\n",
                "# Hypothesize that the proportion of late shipments is 6%\n",
                "p_0 = 0.06\n",
                "\n",
                "# Calculate the sample proportion of late shipments\n",
                "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
                "\n",
                "# Calculate the sample size\n",
                "n = len(late_shipments)\n",
                "\n",
                "# Calculate the numerator and denominator of the test statistic\n",
                "numerator = p_hat - p_0\n",
                "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
                "\n",
                "# Calculate the test statistic\n",
                "z_score = numerator / denominator\n",
                "\n",
                "# Print the result\n",
                "print(z_score)\n",
                "\n",
                "\n",
                "# Hypothesize that the proportion of late shipments is 6%\n",
                "p_0 = 0.06\n",
                "\n",
                "# Calculate the sample proportion of late shipments\n",
                "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
                "\n",
                "# Calculate the sample size\n",
                "n = len(late_shipments)\n",
                "\n",
                "# Calculate the numerator and denominator of the test statistic\n",
                "numerator = p_hat - p_0\n",
                "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
                "\n",
                "# Calculate the test statistic\n",
                "z_score = numerator / denominator\n",
                "\n",
                "# Calculate the p-value from the z-score\n",
                "p_value = 1 - norm.cdf(z_score)\n",
                "\n",
                "# Print the p-value\n",
                "print(p_value)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test of two proportions\n",
                "\n",
                "You may wonder if the amount paid for freight affects whether or not the\n",
                "shipment was late. Recall that in the `late_shipments` dataset, whether\n",
                "or not the shipment was late is stored in the `late` column. Freight\n",
                "costs are stored in the `freight_cost_group` column, and the categories\n",
                "are `\"expensive\"` and `\"reasonable\"`.\n",
                "\n",
                "The hypotheses to test, with `\"late\"` corresponding to the proportion of\n",
                "late shipments for that group, are\n",
                "\n",
                "\\\\H\\_{0}\\\\: \\\\late\\_{\\text{expensive}} - late\\_{\\text{reasonable}} = 0\\\\\n",
                "\n",
                "\\\\H\\_{A}\\\\: \\\\late\\_{\\text{expensive}} - late\\_{\\text{reasonable}} \\>\n",
                "0\\\\\n",
                "\n",
                "`p_hats` contains the estimates of population proportions (sample\n",
                "proportions) for each `freight_cost_group`:\n",
                "\n",
                "    freight_cost_group  late\n",
                "    expensive           Yes     0.082569\n",
                "    reasonable          Yes     0.035165\n",
                "    Name: late, dtype: float64\n",
                "\n",
                "`ns` contains the sample sizes for these groups:\n",
                "\n",
                "    freight_cost_group\n",
                "    expensive     545\n",
                "    reasonable    455\n",
                "    Name: late, dtype: int64\n",
                "\n",
                "`pandas` and `numpy` have been imported under their usual aliases, and\n",
                "`norm` is available from `scipy.stats`.\n",
                "\n",
                "- Calculate the p-value from the z-score.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the pooled sample proportion, \\\\\\hat{p}\\\\, from `p_hats` and\n",
                "  `ns`.\n",
                "\n",
                "\\$\\$ \\hat{p} = \\frac{n\\_{\\text{expensive}} \\times\n",
                "\\hat{p}\\_{\\text{expensive}} + n\\_{\\text{reasonable}} \\times\n",
                "\\hat{p}\\_{\\text{reasonable}}}{n\\_{\\text{expensive}} +\n",
                "n\\_{\\text{reasonable}}} \\$\\$\n",
                "\n",
                "Calculate the standard error of the sample *using this equation.*\n",
                "\n",
                "$$\\text{SE}({\\hat{p}}\\_{\\text{expensive}} - {\\hat{p}}\\_{\\text{reasonable}}) = \\sqrt{\\frac{\\hat{p} \\times (1 - \\hat{p})}{n\\_{\\text{expensive}}} + \\frac{\\hat{p} \\times (1 - \\hat{p})}{n\\_{\\text{reasonable}}}}$$\n",
                "\n",
                "- Calculate `p_hat` multiplied by `(1 - p_hat)`.\n",
                "- Divide `p_hat_times_not_p_hat` by the number of `\"reasonable\"` rows\n",
                "    and by the number of `\"expensive\"` rows, and sum those two values.\n",
                "- Calculate `std_error` by taking the square root of\n",
                "    `p_hat_times_not_p_hat_over_ns`.\n",
                "\n",
                "-   Calculate the z-score *using the following equation.*\n",
                "\n",
                "$$z = \\frac{({\\hat{p}}\\_{\\text{expensive}} - {\\hat{p}}\\_{\\text{reasonable}})}{\\text{SE}({\\hat{p}}\\_{\\text{expensive}} - {\\hat{p}}\\_{\\text{reasonable}})}$$\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the pooled estimate of the population proportion\n",
                "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
                "\n",
                "# Print the result\n",
                "print(p_hat)\n",
                "\n",
                "\n",
                "# Calculate the pooled estimate of the population proportion\n",
                "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
                "\n",
                "# Calculate p_hat one minus p_hat\n",
                "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
                "\n",
                "# Divide this by each of the sample sizes and then sum\n",
                "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
                "\n",
                "# Calculate the standard error\n",
                "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
                "\n",
                "# Print the result\n",
                "print(std_error)\n",
                "\n",
                "\n",
                "# Calculate the pooled estimate of the population proportion\n",
                "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
                "\n",
                "# Calculate p_hat one minus p_hat\n",
                "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
                "\n",
                "# Divide this by each of the sample sizes and then sum\n",
                "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
                "\n",
                "# Calculate the standard error\n",
                "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
                "\n",
                "# Calculate the z-score\n",
                "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
                "\n",
                "# Print z_score\n",
                "print(z_score)\n",
                "\n",
                "\n",
                "# Calculate the pooled estimate of the population proportion\n",
                "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
                "\n",
                "# Calculate p_hat one minus p_hat\n",
                "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
                "\n",
                "# Divide this by each of the sample sizes and then sum\n",
                "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
                "\n",
                "# Calculate the standard error\n",
                "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
                "\n",
                "# Calculate the z-score\n",
                "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
                "\n",
                "# Calculate the p-value from the z-score\n",
                "p_value = 1 - norm.cdf(z_score)\n",
                "\n",
                "# Print p_value\n",
                "print(p_value)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### proportions_ztest() for two samples\n",
                "\n",
                "That took a lot of effort to calculate the p-value, so while it is\n",
                "useful to see how the calculations work, it isn't practical to do in\n",
                "real-world analyses. For daily usage, it's better to use the\n",
                "`statsmodels` package.\n",
                "\n",
                "Recall the hypotheses.\n",
                "\n",
                "\\\\H\\_{0}\\\\: \\\\late\\_{\\text{expensive}} - late\\_{\\text{reasonable}} = 0\\\\\n",
                "\n",
                "\\\\H\\_{A}\\\\: \\\\late\\_{\\text{expensive}} - late\\_{\\text{reasonable}} \\>\n",
                "0\\\\\n",
                "\n",
                "`late_shipments` is available, containing the `freight_cost_group`\n",
                "column. `numpy` and `pandas` have been loaded under their standard\n",
                "aliases, and `proportions_ztest` has been loaded from\n",
                "`statsmodels.stats.proportion`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Get the counts of the `late` column grouped by `freight_cost_group`.\n",
                "- Extract the number of `\"Yes\"`'s for the two `freight_cost_group` into a `numpy` array, specifying the `'expensive'` count and then `'reasonable'`.\n",
                "- Determine the overall number of rows in each `freight_cost_group` as a `numpy` array, specifying the `'expensive'` count and then `'reasonable'`.\n",
                "- Run a z-test using `proportions_ztest()`, specifying `alternative` as `\"larger\"`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the late column values for each freight_cost_group\n",
                "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
                "\n",
                "# Print the counts\n",
                "print(late_by_freight_cost_group)\n",
                "\n",
                "\n",
                "# Count the late column values for each freight_cost_group\n",
                "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
                "\n",
                "# Create an array of the \"Yes\" counts for each freight_cost_group\n",
                "success_counts = np.array([45, 16])\n",
                "\n",
                "# Create an array of the total number of rows in each freight_cost_group\n",
                "n = np.array([45 + 500, 16 + 439])\n",
                "\n",
                "# Run a z-test on the two proportions\n",
                "stat, p_value = proportions_ztest(count=success_counts, nobs=n,\n",
                "                                  alternative=\"larger\")\n",
                "\n",
                "# Print the results\n",
                "print(stat, p_value)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performing a chi-square test\n",
                "\n",
                "The *chi-square independence test* compares proportions of successes of\n",
                "one categorical variable across the categories of another categorical\n",
                "variable.\n",
                "\n",
                "Trade deals often use a form of business shorthand in order to specify\n",
                "the exact details of their contract. These are International Chamber of\n",
                "Commerce (ICC) international commercial terms, or *incoterms* for short.\n",
                "\n",
                "The `late_shipments` dataset includes a `vendor_inco_term` that\n",
                "describes the incoterms that applied to a given shipment. The choices\n",
                "are:\n",
                "\n",
                "- [`EXW`](https://www.investopedia.com/terms/e/exw.asp): \"Ex works\". The\n",
                "  buyer pays for transportation of the goods.\n",
                "- [`CIP`](https://www.investopedia.com/terms/c/carriage-and-insurance-paid-cip.asp):\n",
                "  \"Carriage and insurance paid to\". The seller pays for freight and\n",
                "  insurance until the goods board a ship.\n",
                "- [`DDP`](https://www.investopedia.com/terms/d/delivery-duty-paid.asp):\n",
                "  \"Delivered duty paid\". The seller pays for transportation of the goods\n",
                "  until they reach a destination port.\n",
                "- [`FCA`](https://www.investopedia.com/terms/f/fca.asp): \"Free carrier\".\n",
                "  The seller pays for transportation of the goods.\n",
                "\n",
                "Perhaps the incoterms affect whether or not the freight costs are\n",
                "expensive. Test these hypotheses with a significance level of `0.01`.\n",
                "\n",
                "\\\\H\\_{0}\\\\: `vendor_inco_term` and `freight_cost_group` are independent.\n",
                "\n",
                "\\\\H\\_{A}\\\\: `vendor_inco_term` and `freight_cost_group` are associated.\n",
                "\n",
                "`late_shipments` is available, and the following have been loaded:\n",
                "`matplotlib.pyplot` as `plt`, `pandas` as `pd`, and `pingouin`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the proportion of `freight_cost_group` in `late_shipments`\n",
                "  grouped by `vendor_inco_term`.\n",
                "- Unstack the `.value_counts()` result to be in wide format instead of long.\n",
                "- Create a proportional stacked bar plot with bars filled based on `freight_cost_group` across the levels of `vendor_inco_term`.\n",
                "- Perform a chi-square test of independence on `freight_cost_group` and `vendor_inco_term` in the `late_shipments` dataset.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
                "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
                "\n",
                "# Print props\n",
                "print(props)\n",
                "\n",
                "\n",
                "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
                "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
                "\n",
                "# Convert props to wide format\n",
                "wide_props = props.unstack()\n",
                "\n",
                "# Print wide_props\n",
                "print(wide_props)\n",
                "\n",
                "\n",
                "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
                "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
                "\n",
                "# Convert props to wide format\n",
                "wide_props = props.unstack()\n",
                "\n",
                "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
                "wide_props.plot(kind=\"bar\", stacked=True)\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
                "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
                "\n",
                "# Convert props to wide format\n",
                "wide_props = props.unstack()\n",
                "\n",
                "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
                "wide_props.plot(kind=\"bar\", stacked=True)\n",
                "plt.show()\n",
                "\n",
                "# Determine if freight_cost_group and vendor_inco_term are independent\n",
                "expected, observed, stats = pingouin.chi2_independence(data=late_shipments, x=\"vendor_inco_term\", y=\"freight_cost_group\")\n",
                "\n",
                "# Print results\n",
                "print(stats[stats['test'] == 'pearson']) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing goodness of fit\n",
                "\n",
                "The *chi-square goodness of fit test* compares proportions of each level\n",
                "of a categorical variable to hypothesized values. Before running such a\n",
                "test, it can be helpful to visually compare the distribution in the\n",
                "sample to the hypothesized distribution.\n",
                "\n",
                "Recall the vendor incoterms in the `late_shipments` dataset. You\n",
                "hypothesize that the four values occur with these frequencies in the\n",
                "population of shipments.\n",
                "\n",
                "- `CIP`: 0.05\n",
                "- `DDP`: 0.1\n",
                "- `EXW`: 0.75\n",
                "- `FCA`: 0.1\n",
                "\n",
                "These frequencies are stored in the `hypothesized` DataFrame.\n",
                "\n",
                "The `incoterm_counts` DataFrame stores the `.value_counts()` of the\n",
                "`vendor_inco_term` column.\n",
                "\n",
                "`late_shipments` is available; `pandas` and `matplotlib.pyplot` are\n",
                "loaded with their standard aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Find the total number of rows in `late_shipments`.\n",
                "- Add a column named `n` to the `hypothesized` DataFrame that is the `hypothesized` `prop` column times `n_total`.\n",
                "- Create a bar graph of `'n'` versus `'vendor_inco_term'` for the `incoterm_counts` data, specifying a red color.\n",
                "- Add blue bars to the plot showing the same results from the `hypothesized` DataFrame, specifying an `alpha` of `0.5`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find the number of rows in late_shipments\n",
                "n_total = len(late_shipments)\n",
                "\n",
                "# Print n_total\n",
                "print(n_total)\n",
                "\n",
                "\n",
                "# Find the number of rows in late_shipments\n",
                "n_total = len(late_shipments)\n",
                "\n",
                "# Create n column that is prop column * n_total\n",
                "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
                "\n",
                "# Print the modified hypothesized DataFrame\n",
                "print(hypothesized)\n",
                "\n",
                "\n",
                "# Find the number of rows in late_shipments\n",
                "n_total = len(late_shipments)\n",
                "\n",
                "# Create n column that is prop column * n_total\n",
                "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
                "\n",
                "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
                "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Find the number of rows in late_shipments\n",
                "n_total = len(late_shipments)\n",
                "\n",
                "# Create n column that is prop column * n_total\n",
                "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
                "\n",
                "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
                "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
                "\n",
                "# Add a blue bar plot for the hypothesized counts\n",
                "plt.bar(hypothesized['vendor_inco_term'], hypothesized['n'], alpha=0.5, color=\"blue\", label=\"Hypothesized\")\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performing a goodness of fit test\n",
                "\n",
                "The bar plot of `vendor_inco_term` suggests that the distribution across\n",
                "the four categories was quite close to the hypothesized distribution.\n",
                "You'll need to perform a *chi-square goodness of fit test* to see\n",
                "whether the differences are statistically significant.\n",
                "\n",
                "Recall the hypotheses for this type of test:\n",
                "\n",
                "\\\\H\\_{0}\\\\: The sample matches with the hypothesized distribution.\n",
                "\n",
                "\\\\H\\_{A}\\\\: The sample does not match with the hypothesized\n",
                "distribution.\n",
                "\n",
                "To decide which hypothesis to choose, we'll set a significance level of\n",
                "`0.1`.\n",
                "\n",
                "`late_shipments`, `incoterm_counts`, and `hypothesized` from the last\n",
                "exercise are available. `chisquare` from `scipy.stats` has been loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Using the `incoterm_counts` and `hypothesized` datasets, perform a\n",
                "  chi-square goodness of fit test on the incoterm counts, `n`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform a goodness of fit test on the incoterm counts n\n",
                "gof_test = chisquare(f_obs=incoterm_counts['n'], \n",
                "                     f_exp=hypothesized['n'])\n",
                "\n",
                "# Print gof_test results\n",
                "print(gof_test)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Non-Parametric Tests\n",
                "\n",
                "### Testing sample size\n",
                "\n",
                "In order to conduct a hypothesis test and be sure that the result is\n",
                "fair, a sample must meet three requirements: it is a random sample of\n",
                "the population, the observations are independent, and there are enough\n",
                "observations. Of these, only the last condition is easily testable with\n",
                "code.\n",
                "\n",
                "The minimum sample size depends on the type of hypothesis tests you want\n",
                "to perform. You'll now test some scenarios on the `late_shipments`\n",
                "dataset.\n",
                "\n",
                "Note that the `.all()` method from `pandas` can be used to check if all\n",
                "elements are true. For example, given a DataFrame `df` with numeric\n",
                "entries, you check to see if all its elements are less than `5`, using\n",
                "`(df < 5).all()`.\n",
                "\n",
                "`late_shipments` is available, and `pandas` is loaded as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Get the count of each value in the `freight_cost_group` column of\n",
                "  `late_shipments`.\n",
                "- Insert a suitable number to inspect whether the counts are \"big\n",
                "  enough\" for a two sample t-test.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Get the count of each value in the `late` column of `late_shipments`.\n",
                "- Insert a suitable number to inspect whether the counts are \"big\n",
                "  enough\" for a one sample proportion test.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Get the count of each value in the `freight_cost_group` column of\n",
                "  `late_shipments` grouped by `vendor_inco_term`.\n",
                "- Insert a suitable number to inspect whether the counts are \"big\n",
                "  enough\" for a chi-square independence test.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Get the count of each value in the `shipment_mode` column of\n",
                "  `late_shipments`.\n",
                "- Insert a suitable number to inspect whether the counts are \"big\n",
                "  enough\" for an ANOVA test.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the freight_cost_group values\n",
                "counts = late_shipments['freight_cost_group'].value_counts()\n",
                "\n",
                "# Print the result\n",
                "print(counts)\n",
                "\n",
                "# Inspect whether the counts are big enough\n",
                "print((counts >= 30).all())\n",
                "\n",
                "\n",
                "# Count the late values\n",
                "counts = late_shipments['late'].value_counts()\n",
                "\n",
                "# Print the result\n",
                "print(counts)\n",
                "\n",
                "# Inspect whether the counts are big enough\n",
                "print((counts >= 10).all())\n",
                "\n",
                "\n",
                "# Count the values of freight_cost_group grouped by vendor_inco_term\n",
                "counts = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts()\n",
                "\n",
                "# Print the result\n",
                "print(counts)\n",
                "\n",
                "# Inspect whether the counts are big enough\n",
                "print((counts >= 5).all())\n",
                "\n",
                "\n",
                "# Count the shipment_mode values\n",
                "counts = late_shipments['shipment_mode'].value_counts()\n",
                "\n",
                "# Print the result\n",
                "print(counts)\n",
                "\n",
                "# Inspect whether the counts are big enough\n",
                "print((counts >= 30).all())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wilcoxon signed-rank test\n",
                "\n",
                "You'll explore the difference between the proportion of county-level\n",
                "votes for the Democratic candidate in 2012 and 2016 to identify if the\n",
                "difference is significant.\n",
                "\n",
                "`sample_dem_data` is available, and has columns `dem_percent_12` and\n",
                "`dem_percent_16` in addition to `state` and `county` names. The\n",
                "following packages have also been loaded: `pingouin` and `pandas` as\n",
                "`pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Conduct a paired t-test on the percentage columns using an appropriate\n",
                "  alternative hypothesis.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Conduct a Wilcoxon-signed rank test on the same columns.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conduct a paired t-test on dem_percent_12 and dem_percent_16\n",
                "paired_test_results = pingouin.ttest(x=sample_dem_data['dem_percent_12'], \n",
                "                                     y=sample_dem_data['dem_percent_16'],\n",
                "                                     paired=True,\n",
                "                                     alternative=\"two-sided\")\n",
                "\n",
                "# Print paired t-test results\n",
                "print(paired_test_results)\n",
                "\n",
                "\n",
                "# Conduct a Wilcoxon test on dem_percent_12 and dem_percent_16\n",
                "wilcoxon_test_results = pingouin.wilcoxon(x=sample_dem_data['dem_percent_12'], \n",
                "                                          y=sample_dem_data['dem_percent_16'],\n",
                "                                          alternative=\"two-sided\")\n",
                "\n",
                "# Print Wilcoxon test results\n",
                "print(wilcoxon_test_results)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wilcoxon-Mann-Whitney\n",
                "\n",
                "Another class of non-parametric hypothesis tests are called *rank sum\n",
                "tests*. Ranks are the positions of numeric values from smallest to\n",
                "largest. Think of them as positions in running events: whoever has the\n",
                "fastest (smallest) time is rank 1, second fastest is rank 2, and so on.\n",
                "\n",
                "By calculating on the ranks of data instead of the actual values, you\n",
                "can avoid making assumptions about the distribution of the test\n",
                "statistic. It's more robust in the same way that a median is more robust\n",
                "than a mean.\n",
                "\n",
                "One common rank-based test is the Wilcoxon-Mann-Whitney test, which is\n",
                "like a non-parametric t-test.\n",
                "\n",
                "`late_shipments` is available, and the following packages have been\n",
                "loaded: `pingouin` and `pandas` as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Select `weight_kilograms` and `late` from `late_shipments`, assigning\n",
                "  the name `weight_vs_late`.\n",
                "- Convert `weight_vs_late` from long-to-wide format, setting `columns`\n",
                "  to `'late'`.\n",
                "- Run a Wilcoxon-Mann-Whitney test for a difference in\n",
                "  `weight_kilograms` when the shipment was late and on-time.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select the weight_kilograms and late columns\n",
                "weight_vs_late = late_shipments[[\"weight_kilograms\", \"late\"]]\n",
                "\n",
                "# Convert weight_vs_late into wide format\n",
                "weight_vs_late_wide = weight_vs_late.pivot(columns='late', \n",
                "                                           values='weight_kilograms')\n",
                "\n",
                "# Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late\n",
                "wmw_test = pingouin.mwu(x=weight_vs_late_wide['No'],\n",
                "                        y=weight_vs_late_wide['Yes'],\n",
                "                        alternative='two-sided')\n",
                "\n",
                "# Print the test results\n",
                "print(wmw_test)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Kruskal-Wallis\n",
                "\n",
                "Recall that the Kruskal-Wallis test is a non-parametric version of an\n",
                "ANOVA test, comparing the means across multiple groups.\n",
                "\n",
                "`late_shipments` is available, and the following packages have been\n",
                "loaded: `pingouin` and `pandas` as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Run a Kruskal-Wallis test on `weight_kilograms` between the different\n",
                "  shipment modes in `late_shipments`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run a Kruskal-Wallis test on weight_kilograms vs. shipment_mode\n",
                "kw_test = pingouin.kruskal(data=late_shipments, \n",
                "                           dv='weight_kilograms',\n",
                "                           between='shipment_mode')\n",
                "\n",
                "# Print the results\n",
                "print(kw_test)\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
